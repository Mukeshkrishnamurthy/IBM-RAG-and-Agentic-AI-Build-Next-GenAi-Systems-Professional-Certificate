{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG2 101 (AutoGen): Complete Tutorial\n",
    "\n",
    "Estimated time needed: **45** minutes\n",
    "\n",
    "This notebook provides a comprehensive guide to AG2 (formerly AutoGen) basic concepts with runnable examples and detailed explanations. AG2 is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Setup-and-Import\">Setup and Import</a></li>\n",
    "    <li><a href=\"#Configure-API-Keys\">Configure API Keys</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Introduction-to-Agent-Concepts\">Introduction to Agent Concepts</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Conversable-Agent\">Conversable Agent</a></li>\n",
    "            <li><a href=\"#Creating-Specialized-Agents\">Creating Specialized Agents</a></li>\n",
    "            <li><a href=\"#Built-in-Agent-Types\">Built-in Agent Types</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Human-in-the-Loop\">Human-in-the-Loop</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Agent-Orchestration-&-Multi-Agent-Systems-in-AG2\">Agent Orchestration & Multi-Agent Systems in AG2</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#GroupChat-and-GroupChatManager\">GroupChat and GroupChatManager</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Tools-and-Extensions\">Tools and Extensions</a></li>\n",
    "    <li><a href=\"#Structured-Outputs\">Structured Outputs</a></li>\n",
    "    <li><a href=\"#Best-Practices\">Best Practices</a></li>\n",
    "    <li><a href=\"#Conclusion\">Conclusion</a></li>\n",
    "    <li><a href=\"#Authors\">Authors</a></li>\n",
    "    \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Import\n",
    "\n",
    "Here we install AG2, import the required modules, and load the environment variables.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed ag2-0.10.3 diskcache-5.6.3 docker-7.1.0 jiter-0.12.0 openai-2.14.0 python-dotenv-1.2.1 regex-2025.11.3 termcolor-3.2.0 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ag2[openai] python-dotenv | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AG2 modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from autogen import ConversableAgent, AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "from autogen.llm_config import LLMConfig\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"AG2 modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Suppress API key format warning\n",
    "logging.getLogger(\"autogen.oai.client\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure API Keys\n",
    "\n",
    "Autogen supports various LLM providers. Let's set up configuration for OpenAI.  \n",
    "\n",
    "**Note:** In this environment, you do not need to run this cell and you can skip to the next section. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a configuration file for your API keys\n",
    "# # Replace with your actual API key\n",
    "# config_list = [\n",
    "#     {\n",
    "#         \"model\": \"gpt-4\",\n",
    "#         #\"api_key\": \"\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# Alternatively, you can create a JSON file\n",
    "# '''\n",
    "# with open('config.json', 'w') as f:\n",
    "#    json.dump(config_list, f)\n",
    "    \n",
    "# Then load it\n",
    "# config_list = config_list_from_json(\"config.json\")\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Agent Concepts\n",
    "\n",
    "We have several agent concepts in AG2 to help you build your AI agents. We introduce the most common ones here:\n",
    "\n",
    "- **Conversable agent**: Agents that are able to send messages, receive messages and generate replies using GenAI models, non-GenAI tools, or human inputs.\n",
    "\n",
    "- **Human in the loop**: Add human input to the conversation.\n",
    "\n",
    "- **Orchestrating multiple agents**: Users can orchestrate multiple agents with built-in conversation patterns such as swarms, group chats, nested chats, sequential chats or customize the orchestration by registering custom reply methods.\n",
    "\n",
    "- **Tools**: Programs that can be registered, invoked and executed by agents.\n",
    "\n",
    "- **Advanced concepts**: AG2 supports more concepts such as structured outputs, RAG, code execution, and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversable Agent\n",
    "\n",
    "The ConversableAgent is the fundamental building block of AG2, designed to enable seamless communication between AI entities. This core agent type handles message exchange and response generation, serving as the base class for all agents in the framework.\n",
    "\n",
    "#### Key characteristics:\n",
    "- **Communication**: Can send and receive messages\n",
    "- **Processing**: Handles information and generates responses\n",
    "- **Personality**: Defined by system messages\n",
    "- **Flexibility**: Base for all other agent types\n",
    "\n",
    "In the example below, we'll create a simple information validation workflow with two specialized agents that communicate with each other.\n",
    "\n",
    "**Note**: `initiate_chat()` starts a conversation with another agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mstudent\u001b[0m (to tutor):\n",
      "\n",
      "Can you explain what a neural network is?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/2505849586.py:7: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtutor\u001b[0m (to student):\n",
      "\n",
      "Sure! A neural network is a type of computer system designed to recognize patterns and make decisions based on data. It is inspired by the structure and functioning of the human brain.\n",
      "\n",
      "Hereâ€™s a simple breakdown of how it works:\n",
      "\n",
      "1. **Neurons**: Just like the brain is made up of neurons, a neural network is made up of artificial neurons (also called nodes). Each neuron receives input, processes it, and produces output.\n",
      "\n",
      "2. **Layers**: Neurons are organized into layers:\n",
      "   - **Input Layer**: This is where the network receives data. Each neuron in this layer corresponds to a feature of the input.\n",
      "   - **Hidden Layers**: These layers are between the input and output layers. They process the inputs received from the previous layer. A neural network can have one or many hidden layers.\n",
      "   - **Output Layer**: This layer produces the final output, which could be a classification, a prediction, or another type of result, depending on the task.\n",
      "\n",
      "3. **Connections and Weights**: Neurons in one layer are connected to those in the next layer. Each connection has a weight, which is a value that adjusts the importance of the input. During training, these weights are adjusted based on the data to improve accuracy.\n",
      "\n",
      "4. **Activation Function**: Each neuron uses an activation function to determine whether it should \"fire\" (produce output) based on the input it receives. This helps introduce non-linearity into the network, allowing it to learn complex patterns.\n",
      "\n",
      "5. **Training**: Neural networks learn from data through a process called training, which typically involves:\n",
      "   - Feeding input data into the network.\n",
      "   - Calculating the output and comparing it to the expected result.\n",
      "   - Using a method called backpropagation to adjust the weights based on the errors, so the network gets better over time.\n",
      "\n",
      "In summary, a neural network processes input data through interconnected layers of artificial neurons to learn patterns, allowing it to make predictions or decisions. They're widely used in tasks like image recognition, natural language processing, and more!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:156\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 156\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_backends/sync.py:154\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m    150\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    151\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    153\u001b[0m }\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     16\u001b[0m     tutor \u001b[38;5;241m=\u001b[39m ConversableAgent(\n\u001b[1;32m     17\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtutor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m         system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful tutor who provides clear and concise explanations suitable for a beginner.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m         human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEVER\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 3: Start a 2-turn conversation initiated by the student\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m \u001b[43mstudent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# who the student is talking to\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCan you explain what a neural network is?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the student's question\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                     \u001b[49m\u001b[38;5;66;43;03m# total number of back-and-forth messages\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# generate a final summary using LLM\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Step 4: Print the summary of the conversation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1457\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_terminate_chat(recipient, last_message):\n\u001b[1;32m   1456\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1457\u001b[0m     msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecipient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2881\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2881\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2883\u001b[0m         log_event(\n\u001b[1;32m   2884\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2885\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2890\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2162\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config, **kwargs)\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM call blocked by safeguard\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2162\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;66;03m# Process LLM response\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2197\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 2197\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2204\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:1263\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m-> 1263\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m openai_result\u001b[38;5;241m.\u001b[39mis_successful:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:684\u001b[0m, in \u001b[0;36mOpenAIClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_reasoning_model_params(params)\n\u001b[1;32m    683\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_or_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# remove the system_message from the response and add it in the prompt at the start.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_o1:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:455\u001b[0m, in \u001b[0;36mOpenAIClient._handle_openai_bad_request_error.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m OpenAIClient\u001b[38;5;241m.\u001b[39m_patch_messages_for_deepseek_reasoner(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    457\u001b[0m     response_json \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:1014\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# Step 1: Define the LLM configuration\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Step 2: Define our two agents â€” a student and a tutor\n",
    "with llm_config:\n",
    "    # Create the student agent (asks questions)\n",
    "    student = ConversableAgent(\n",
    "        name=\"student\",\n",
    "        system_message=\"You are a curious student. You ask clear, specific questions to learn new concepts.\",\n",
    "        human_input_mode=\"NEVER\"  # disables manual input during chat\n",
    "    )\n",
    "\n",
    "    # Create the tutor agent (responds with beginner-friendly answers)\n",
    "    tutor = ConversableAgent(\n",
    "        name=\"tutor\",\n",
    "        system_message=\"You are a helpful tutor who provides clear and concise explanations suitable for a beginner.\",\n",
    "        human_input_mode=\"NEVER\"\n",
    "    )\n",
    "\n",
    "# Step 3: Start a 2-turn conversation initiated by the student\n",
    "chat_result = student.initiate_chat(\n",
    "    recipient=tutor,                                # who the student is talking to\n",
    "    message=\"Can you explain what a neural network is?\",  # the student's question\n",
    "    max_turns=2,                                     # total number of back-and-forth messages\n",
    "    summary_method=\"reflection_with_llm\"            # generate a final summary using LLM\n",
    ")\n",
    "\n",
    "# Step 4: Print the summary of the conversation\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(chat_result.summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Add summary_method=`\"reflection_with_llm\"`?\n",
    "\n",
    "By enabling summary_method=`\"reflection_with_llm\"`, we allow the system to generate a final response that is not simply a direct answer, but a **reflection of a structured conversation** between multiple agents with defined roles.\n",
    "\n",
    "In this case, instead of prompting an LLM directly with *â€œWhat is a neural network?â€*, the system simulates a conversation where:\n",
    "- A **student** asks a clear question,\n",
    "- A **tutor** responds with a beginner-friendly explanation,\n",
    "- And the LLM reflects on this interaction to generate a detailed and coherent summary.\n",
    "  \n",
    "This approach can also be extended to **solve complex tasks** by simulating a structured conversation between **expert agents** (for example, a data scientist, a software engineer, and a business strategist), each contributing from their expertise to build a better solution.\n",
    "\n",
    "This often produces **higher-quality, context-rich answers**, as the reasoning is distributed and clarified through role-based collaboration.  \n",
    "\n",
    "**Note:** You can try running the conversation without adding the line `summary_method=\"reflection_with_llm\"` and see the difference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Specialized Agents\n",
    "\n",
    "The power of ConversableAgent comes from customization. Let's create agents with different personalities and purposes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialized agents created!\n",
      "- tech_expert: You are a senior software engineer with expertise in Python, AI, and system design.\n",
      "- creative_writer: You are a creative writer and storyteller.\n",
      "- business_analyst: You are a business analyst focused on ROI, efficiency, and strategic planning.\n"
     ]
    }
   ],
   "source": [
    "# Create a Technical Expert Agent\n",
    "tech_expert = ConversableAgent(\n",
    "    name=\"tech_expert\",\n",
    "    system_message=\"\"\"You are a senior software engineer with expertise in Python, AI, and system design.\n",
    "    Provide technical, detailed explanations with code examples when appropriate.\n",
    "    Always consider best practices and performance implications.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Create a Creative Writer Agent\n",
    "creative_writer = ConversableAgent(\n",
    "    name=\"creative_writer\",\n",
    "    system_message=\"\"\"You are a creative writer and storyteller.\n",
    "    Your responses are engaging, imaginative, and use vivid descriptions.\n",
    "    You excel at making complex topics accessible through stories and analogies.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "# Create a Business Analyst Agent\n",
    "business_analyst = ConversableAgent(\n",
    "    name=\"business_analyst\",\n",
    "    system_message=\"\"\"You are a business analyst focused on ROI, efficiency, and strategic planning.\n",
    "    Always consider business impact, costs, and practical implementation.\n",
    "    Provide actionable recommendations with clear metrics.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "agents = [tech_expert, creative_writer, business_analyst]\n",
    "print(\"Specialized agents created!\")\n",
    "for agent in agents:\n",
    "    print(f\"- {agent.name}: {agent.system_message.split('.')[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Agent Types\n",
    "\n",
    "AG2 provides specialized agent classes built on `ConversableAgent` to streamline common workflows such as task-solving, tool use, and user interaction.\n",
    "\n",
    "#### AssistantAgent â€” Task-solving LLM assistant\n",
    "\n",
    "`AssistantAgent` is a subclass of `ConversableAgent` configured with a default system message tailored for solving tasks using LLMs. It can suggest Python code blocks, offer debugging suggestions, and provide structured responses.\n",
    "\n",
    "- `human_input_mode`: Defaults to `\"NEVER\"` â€” the assistant operates autonomously.\n",
    "- `code_execution_config`: Defaults to `False` â€” it does **not execute code** itself.\n",
    "- Designed to work collaboratively with other agents (for example, `UserProxyAgent`) that handle execution.\n",
    "\n",
    "This agent excels at reasoning, planning, and generating code â€” and expects others to handle the execution layer.\n",
    "\n",
    "#### UserProxyAgent â€” Executing code on behalf of the user\n",
    "\n",
    "`UserProxyAgent` is a subclass of `ConversableAgent` that acts as a proxy for the human user. It is designed to **execute code**, simulate user decisions, and provide execution-based feedback to other agents like `AssistantAgent`.\n",
    "\n",
    "- `human_input_mode`: Defaults to `\"ALWAYS\"` â€” prompts the user at every turn.\n",
    "- `llm_config`: Defaults to `False` â€” no LLM responses unless explicitly configured.\n",
    "- **Code execution is enabled by default.**\n",
    "\n",
    "You can customize its behavior by:\n",
    "- Registering an auto-reply function via `.register_reply()`.\n",
    "- Overriding `.get_human_input()` to change how user input is gathered.\n",
    "- Overriding `.execute_code_blocks()`, `.run_code()`, or `.execute_function()` to control code execution behavior.\n",
    "\n",
    "These two agents are often paired: the `AssistantAgent` writes code, and the `UserProxyAgent` executes it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Plot a sine wave using matplotlib from -2Ï€ to 2Ï€ and save the plot as sine_wave.png.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/2512516738.py:12: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To plot a sine wave using Matplotlib and save the plot as `sine_wave.png`, you can follow these steps in Python:\n",
      "\n",
      "1. Import the necessary libraries.\n",
      "2. Create the data points for the sine wave.\n",
      "3. Plot the sine wave.\n",
      "4. Save the plot as a PNG file.\n",
      "\n",
      "Here is the complete Python code to accomplish this:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the range for x values from -2Ï€ to 2Ï€\n",
      "x = np.linspace(-2 * np.pi, 2 * np.pi, 1000)  # 1000 points for a smooth curve\n",
      "y = np.sin(x)  # Compute the sine of each x value\n",
      "\n",
      "# Create the plot\n",
      "plt.figure(figsize=(10, 5))  # Optional: Create a figure with a specific size\n",
      "plt.plot(x, y, label='Sine Wave', color='b')  # Label and color the sine wave\n",
      "plt.title('Sine Wave from -2Ï€ to 2Ï€')  # Title of the plot\n",
      "plt.xlabel('x values (radians)')  # Label for the x-axis\n",
      "plt.ylabel('sin(x)')  # Label for the y-axis\n",
      "plt.axhline(0, color='black', linewidth=0.5, ls='--')  # Add a horizontal line at y=0\n",
      "plt.axvline(0, color='black', linewidth=0.5, ls='--')  # Add a vertical line at x=0\n",
      "plt.grid(True)  # Enable the grid\n",
      "plt.legend()  # Show the legend\n",
      "\n",
      "# Save the plot as a PNG file\n",
      "plt.savefig('sine_wave.png')\n",
      "\n",
      "# Optionally, you can display the plot\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "\n",
      "- **Imports**: The code imports two libraries: `numpy` for numerical operations and `matplotlib.pyplot` for plotting.\n",
      "- **Data Generation**:\n",
      "  - `np.linspace(-2 * np.pi, 2 * np.pi, 1000)` generates 1000 equally spaced points between `-2Ï€` and `2Ï€`.\n",
      "  - `np.sin(x)` computes the sine values for all `x` points.\n",
      "- **Plotting**:\n",
      "  - `plt.plot()` is used to plot `x` versus `y` (sine values).\n",
      "  - The plot has labels and a title, and a grid is enabled for better readability.\n",
      "- **Saving the Plot**: `plt.savefig('sine_wave.png')` saves the plot in the current working directory.\n",
      "- **Display**: `plt.show()` is optional and allows you to view the plot in a window (not necessary if just saving).\n",
      "\n",
      "Make sure you have `matplotlib` and `numpy` installed in your Python environment. You can install them using pip if you haven't done so:\n",
      "\n",
      "```bash\n",
      "pip install matplotlib numpy\n",
      "```\n",
      "\n",
      "Run the above code to generate and save the sine wave plot as `sine_wave.png`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING 2 CODE BLOCKS (inferred languages are [python, bash])...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: Traceback (most recent call last):\n",
      "  File \"/resources/AI0324EN/coding/tmp_code_484bd6c20bdda63e5d05c319810b202e.py\", line 1, in <module>\n",
      "    import numpy as np\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "It looks like the environment you're using does not have the `numpy` library installed, which is necessary for generating the sine wave data. Similarly, you will also need `matplotlib` to create and save the plot. \n",
      "\n",
      "If you're unable to install packages in your current environment but still want to plot the sine wave, you can use a local Python installation (on your computer) where you can easily install packages.\n",
      "\n",
      "Hereâ€™s how you can set it up step-by-step in your local environment:\n",
      "\n",
      "### Step 1: Install Required Libraries\n",
      "\n",
      "Open your terminal or command prompt and run the following commands:\n",
      "\n",
      "```bash\n",
      "pip install numpy matplotlib\n",
      "```\n",
      "\n",
      "### Step 2: Save and Run the Code\n",
      "\n",
      "Copy the code provided earlier into a Python file, for example, `plot_sine_wave.py`:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the range for x values from -2Ï€ to 2Ï€\n",
      "x = np.linspace(-2 * np.pi, 2 * np.pi, 1000)  # 1000 points for a smooth curve\n",
      "y = np.sin(x)  # Compute the sine of each x value\n",
      "\n",
      "# Create the plot\n",
      "plt.figure(figsize=(10, 5))  # Optional: Create a figure with a specific size\n",
      "plt.plot(x, y, label='Sine Wave', color='b')  # Label and color the sine wave\n",
      "plt.title('Sine Wave from -2Ï€ to 2Ï€')  # Title of the plot\n",
      "plt.xlabel('x values (radians)')  # Label for the x-axis\n",
      "plt.ylabel('sin(x)')  # Label for the y-axis\n",
      "plt.axhline(0, color='black', linewidth=0.5, ls='--')  # Add a horizontal line at y=0\n",
      "plt.axvline(0, color='black', linewidth=0.5, ls='--')  # Add a vertical line at x=0\n",
      "plt.grid(True)  # Enable the grid\n",
      "plt.legend()  # Show the legend\n",
      "\n",
      "# Save the plot as a PNG file\n",
      "plt.savefig('sine_wave.png')\n",
      "\n",
      "# Optionally, you can display the plot\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "### Step 3: Run the Code\n",
      "\n",
      "After saving the file, run it using Python:\n",
      "\n",
      "```bash\n",
      "python plot_sine_wave.py\n",
      "```\n",
      "\n",
      "### Expected Outcome\n",
      "\n",
      "If everything goes well, this should create a sine wave plot and save it as `sine_wave.png` in the current directory.\n",
      "\n",
      "If you still face issues or if you are using a specific online platform that does not allow installation of additional packages, please let me know. There may be alternative methods to visualize the data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING 3 CODE BLOCKS (inferred languages are [bash, python, bash])...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 2 (execution failed)\n",
      "Code output: Figure(1000x500)\n",
      "python: can't open file '/resources/AI0324EN/coding/plot_sine_wave.py': [Errno 2] No such file or directory\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "It seems like you're trying to run a Python script in an environment where either the script does not exist or there's a limitation in executing scripts directly as files. \n",
      "\n",
      "To troubleshoot:\n",
      "\n",
      "1. **Run the Code in an Interactive Environment**: If you're in an interactive environment such as Jupyter Notebook, Google Colab, or a Python shell, you can execute the code directly in the interface. Remove the file operations and run the code directly in a cell:\n",
      "\n",
      "   ```python\n",
      "   import numpy as np\n",
      "   import matplotlib.pyplot as plt\n",
      "\n",
      "   # Define the range for x values from -2Ï€ to 2Ï€\n",
      "   x = np.linspace(-2 * np.pi, 2 * np.pi, 1000)  # 1000 points for a smooth curve\n",
      "   y = np.sin(x)  # Compute the sine of each x value\n",
      "\n",
      "   # Create the plot\n",
      "   plt.figure(figsize=(10, 5))  # Optional: Create a figure with a specific size\n",
      "   plt.plot(x, y, label='Sine Wave', color='b')  # Label and color the sine wave\n",
      "   plt.title('Sine Wave from -2Ï€ to 2Ï€')  # Title of the plot\n",
      "   plt.xlabel('x values (radians)')  # Label for the x-axis\n",
      "   plt.ylabel('sin(x)')  # Label for the y-axis\n",
      "   plt.axhline(0, color='black', linewidth=0.5, ls='--')  # Add a horizontal line at y=0\n",
      "   plt.axvline(0, color='black', linewidth=0.5, ls='--')  # Add a vertical line at x=0\n",
      "   plt.grid(True)  # Enable the grid\n",
      "   plt.legend()  # Show the legend\n",
      "\n",
      "   # Save the plot as a PNG file\n",
      "   plt.savefig('sine_wave.png')\n",
      "\n",
      "   # Optionally, you can display the plot\n",
      "   plt.show()\n",
      "   ```\n",
      "\n",
      "2. **Use Online Platforms**: If you're using an online coding environment, such as [Google Colab](https://colab.research.google.com/), you can simply paste the above code into a code cell and run it. Google Colab has `numpy` and `matplotlib` pre-installed.\n",
      "\n",
      "3. **Check File Operations**: If you only want to display the plot temporarily without saving it, you can skip the `plt.savefig('sine_wave.png')` line. This way, you can just run the plotting part:\n",
      "\n",
      "   ```python\n",
      "   plt.show()  # This will display the plot on the screen.\n",
      "   ```\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "If you're still facing issues, please let me know the specific environment you're using (like a specific IDE, Jupyter Notebook, a cloud service, etc.) so I can provide more tailored guidance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING 2 CODE BLOCKS (inferred languages are [python, python])...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output:   File \"/resources/AI0324EN/coding/tmp_code_4589c7f7759dfda04bedf4474ac5217d.py\", line 1\n",
      "    import numpy as np\n",
      "IndentationError: unexpected indent\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The error message you're seeing indicates that there is an unexpected indent in the code. In Python, indentation is significant, and any excess or misaligned indentation can cause an error.\n",
      "\n",
      "Here's a clean version of the code without any indentation issues. Make sure to copy and paste it directly, ensuring no extra spaces or tabs are included at the start of any line, especially the first line:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the range for x values from -2Ï€ to 2Ï€\n",
      "x = np.linspace(-2 * np.pi, 2 * np.pi, 1000)  # 1000 points for a smooth curve\n",
      "y = np.sin(x)  # Compute the sine of each x value\n",
      "\n",
      "# Create the plot\n",
      "plt.figure(figsize=(10, 5))  # Optional: Create a figure with a specific size\n",
      "plt.plot(x, y, label='Sine Wave', color='b')  # Label and color the sine wave\n",
      "plt.title('Sine Wave from -2Ï€ to 2Ï€')  # Title of the plot\n",
      "plt.xlabel('x values (radians)')  # Label for the x-axis\n",
      "plt.ylabel('sin(x)')  # Label for the y-axis\n",
      "plt.axhline(0, color='black', linewidth=0.5, ls='--')  # Add a horizontal line at y=0\n",
      "plt.axvline(0, color='black', linewidth=0.5, ls='--')  # Add a vertical line at x=0\n",
      "plt.grid(True)  # Enable the grid\n",
      "plt.legend()  # Show the legend\n",
      "\n",
      "# Save the plot as a PNG file\n",
      "plt.savefig('sine_wave.png')\n",
      "\n",
      "# Optionally, you can display the plot\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "### Steps to Ensure No Indentation Issues:\n",
      "\n",
      "1. **Copy the Code Correctly**: Make sure you copy the code without additional spaces or tabs at the beginning of any line.\n",
      "   \n",
      "2. **No Leading Spaces**: Ensure that the first line (`import numpy as np`) has no spaces or tabs before it.\n",
      "\n",
      "3. **Run in a Suitable Environment**: Copy the complete code above into your Python environment and execute it.\n",
      "\n",
      "4. **Remove Errors**: If this happens again, you might want to check if your code editor is adding extra spaces automatically or affecting indentation somehow.\n",
      "\n",
      "Once you paste it correctly, you should be able to run it without indentation errors. If you still run into issues, please describe your setup further or simply run the code without saving it and just showing it. Let me know how it works out!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (25ef4e16-9065-42ce-9bb5-a12b798a6e09): Maximum turns (4) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Summary:\n",
      "The conversation covered how to plot a sine wave using Matplotlib and save it as a PNG file, with specific emphasis on troubleshooting errors related to missing libraries and indentation issues. It provided step-by-step instructions for running Python code locally or in an interactive environment, highlighting the importance of proper indentation and ensuring required libraries are installed. It also suggested using online platforms like Google Colab for easier execution without installation concerns.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Requirements:\n",
    "# !pip install matplotlib numpy  # first run without installing the libraries and see if the agent installs the required libraries itself.\n",
    "\n",
    "from autogen import AssistantAgent, UserProxyAgent, LLMConfig\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# Step 1: Configure the LLM to use (e.g., GPT-4o Mini via OpenAI)\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Step 2: Create the assistant agent (code-writing AI)\n",
    "with llm_config:\n",
    "    assistant = AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=\"You are a helpful assistant who writes and explains Python code clearly.\"\n",
    "    )\n",
    "\n",
    "# Step 3: Create the user agent that can execute code\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",  # Automatically executes code without human input\n",
    "    max_consecutive_auto_reply=5,  # Ends after 5 response cycles (assistant + user_proxy turns)\n",
    "    code_execution_config={\n",
    "        \"executor\": LocalCommandLineCodeExecutor(work_dir=\"coding\", timeout=30),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Step 4: Start a simple task that leads to code generation and execution\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"Plot a sine wave using matplotlib from -2Ï€ to 2Ï€ and save the plot as sine_wave.png.\"\"\",\n",
    "    max_turns=4,  # 2 rounds of assistant â†” user_proxy\n",
    "    summary_method=\"reflection_with_llm\"  # Optional: final LLM-generated summary\n",
    ")\n",
    "\n",
    "# Step 5: Display the generated figure (optional for notebook environments)\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "image_path = \"coding/sine_wave.png\"\n",
    "if os.path.exists(image_path):\n",
    "    display(Image(filename=image_path))\n",
    "else:\n",
    "    print(\"Plot not found. Please check if the assistant saved the file correctly.\")\n",
    "\n",
    "# Step 6: Print summary\n",
    "print(\"\\n Final Summary:\")\n",
    "print(chat_result.summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop\n",
    "\n",
    "AG2 makes integrating human feedback seamless through its human-in-the-loop functionality, allowing AI agents to collaborate with humans during workflows.  \n",
    "\n",
    "This is crucial for:   \n",
    "\n",
    "- **Critical decisions** requiring human judgment\n",
    "- **High-stakes scenarios** with significant consequences\n",
    "- **Regulatory compliance** requiring human oversight\n",
    "- **Quality assurance** and validation\n",
    "\n",
    "You can configure how and when human input is solicited using the `human_input_mode` parameter:\n",
    "\n",
    "- ALWAYS: Requires human input for every response\n",
    "\n",
    "- NEVER: Operates autonomously without human involvement\n",
    "\n",
    "- TERMINATE: Only requests human input to end conversations\n",
    "\n",
    "For convenience, AG2 provides the specialized `UserProxyAgent` class that automatically sets `human_input_mode` to ALWAYS and supports **code execution**. \n",
    "\n",
    "**important note**: Always use code execution functionality with caution and at your own discretion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-the-Loop Example: Bug Triage Bot\n",
    "\n",
    "This example demonstrates how to use AG2â€™s `ConversableAgent` in `human_input_mode=\"ALWAYS\"` to enable **human-in-the-loop workflows**.\n",
    "\n",
    "We simulate a **bug triage assistant** (`triage_bot`) that classifies bug reports as either:\n",
    "- Escalate (for example, critical crash or security issue),\n",
    "- Close (for example, minor cosmetic issue),\n",
    "- Medium priority (default for others).\n",
    "\n",
    "For each classification, the assistant **asks the human agent for confirmation or correction**. This ensures the AI doesnâ€™t act on high-impact decisions without oversight.\n",
    "\n",
    "At the end, the assistant summarizes the triage results.\n",
    "\n",
    "---\n",
    "\n",
    "### Try these inputs when prompted\n",
    "\n",
    "When youâ€™re prompted to reply as the human agent, try responding with the following:\n",
    "\n",
    "- **Confirm assistantâ€™s suggestion**  \n",
    "  `\"Yes, escalate it.\"`  \n",
    "  `\"Closing this makes sense.\"`\n",
    "\n",
    "- **Override assistantâ€™s suggestion**  \n",
    "  `\"This should be marked as high priority instead.\"`  \n",
    "  `\"Letâ€™s keep this open for now.\"`\n",
    "\n",
    "- **Ask for clarification**  \n",
    "  `\"Why do you think this is low priority?\"`  \n",
    "  `\"Can you provide more reasoning?\"`\n",
    "\n",
    "You can also type `exit` at any time to end the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman\u001b[0m (to triage_bot):\n",
      "\n",
      "Please triage the following bug reports one by one:\n",
      "\n",
      "1. App crashes when opening user profile.\n",
      "2. Password reset email not sent consistently.\n",
      "3. Database connection timeout under heavy load.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/3094877594.py:23: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtriage_bot\u001b[0m (to human):\n",
      "\n",
      "1. Bug Report: App crashes when opening user profile.  \n",
      "**Action:** This is an urgent issue as it involves a crash. I will escalate this and ask for confirmation from the human agent.\n",
      "\n",
      "2. Bug Report: Password reset email not sent consistently.  \n",
      "**Action:** This seems to be a medium priority issue. I will classify it as medium and ask the human for review.\n",
      "\n",
      "3. Bug Report: Database connection timeout under heavy load.  \n",
      "**Action:** This is also a medium priority issue. I will classify it as medium and ask the human for review.\n",
      "\n",
      "### Summary of actions taken:\n",
      "- **Escalated:** App crashes when opening user profile.\n",
      "- **Medium Priority:** Password reset email not sent consistently.\n",
      "- **Medium Priority:** Database connection timeout under heavy load.\n",
      "\n",
      "You can type exit to finish.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as human. Provide feedback to triage_bot. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (07f13e2f-d311-4ecc-b9b1-1fced8736785): User requested to end the conversation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, LLMConfig\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "# Step 1: Configure the LLM to use (e.g., GPT-4o Mini via OpenAI)\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Step 2: Define system message for bug triage assistant\n",
    "triage_system_message = \"\"\"\n",
    "You are a bug triage assistant. You will be given bug report summaries.\n",
    "\n",
    "For each bug:\n",
    "- If it is urgent (e.g., 'crash', 'security', or 'data loss' is mentioned), escalate it and ask the human agent for confirmation.\n",
    "- If it seems minor (e.g., cosmetic, typo), suggest closing it but still ask for human review.\n",
    "- Otherwise, classify it as medium priority and ask the human for review.\n",
    "\n",
    "Once all bugs are processed, summarize what was escalated, closed, or marked as medium priority.\n",
    "End by saying: \"You can type exit to finish.\"\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Create the assistant agent\n",
    "with llm_config:\n",
    "    triage_bot = ConversableAgent(\n",
    "        name=\"triage_bot\",\n",
    "        system_message=triage_system_message,\n",
    "    )\n",
    "\n",
    "# Step 4: Create the human agent who will review each recommendation\n",
    "human = ConversableAgent(\n",
    "    name=\"human\",\n",
    "    human_input_mode=\"ALWAYS\",  # prompts for input at each step\n",
    ")\n",
    "\n",
    "# Step 5: Generate sample bug reports\n",
    "BUGS = [\n",
    "    \"App crashes when opening user profile.\",\n",
    "    \"Minor UI misalignment on settings page.\",\n",
    "    \"Password reset email not sent consistently.\",\n",
    "    \"Typo in the About Us footer text.\",\n",
    "    \"Database connection timeout under heavy load.\",\n",
    "    \"Login form allows SQL injection attack.\",\n",
    "]\n",
    "\n",
    "random.shuffle(BUGS)\n",
    "selected_bugs = BUGS[:3]\n",
    "\n",
    "# Format the initial task\n",
    "initial_prompt = (\n",
    "    \"Please triage the following bug reports one by one:\\n\\n\" +\n",
    "    \"\\n\".join([f\"{i+1}. {bug}\" for i, bug in enumerate(selected_bugs)])\n",
    ")\n",
    "\n",
    "# Step 6: Start the conversation\n",
    "response = human.run(\n",
    "    recipient=triage_bot,\n",
    "    message=initial_prompt,\n",
    ")\n",
    "\n",
    "# Step 7: Display the response\n",
    "response.process()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Orchestration & Multi-Agent Systems in AG2<a name=\"agent-orchestration\"></a>\n",
    "\n",
    "AG2 enables the coordination of multiple intelligent agents to collaboratively solve complex tasks. This is known as **agent orchestration** â€” a powerful design pattern where each agent plays a specialized role, and a **group manager** handles the conversation flow.\n",
    "\n",
    "### Why Multi-Agent Systems?\n",
    "\n",
    "Many real-world problems require more than just a single AI assistant. With AG2, you can:\n",
    "\n",
    "- Assign specific roles and responsibilities to different agents.\n",
    "- Orchestrate conversations using built-in patterns (for example, Auto, RoundRobin, Manual).\n",
    "- Enable agents to build on each other's outputs and refine ideas.\n",
    "- Incorporate human agents for oversight, decisions, or approval.\n",
    "\n",
    "### Orchestration Patterns in AG2\n",
    "\n",
    "AG2 provides several orchestration patterns to structure agent interactions:\n",
    "\n",
    "- **Two-Agent Chat**: Simple back-and-forth between two agents.\n",
    "- **Sequential Chat**: Conversations where one agentâ€™s output becomes anotherâ€™s input.\n",
    "- **Group Chat**: Multiple agents interact, with selection logic for who speaks next.\n",
    "- **Nested Chat**: Reusable sub-conversations packaged as a single workflow.\n",
    "\n",
    "---\n",
    "\n",
    "## GroupChat and GroupChatManager\n",
    "\n",
    "In AG2, multi-agent collaboration is coordinated using `GroupChat` and `GroupChatManager`.\n",
    "\n",
    "### GroupChat\n",
    "\n",
    "`GroupChat` defines a team of agents and how they interact in a shared conversation. It includes:\n",
    "\n",
    "- **Agents**: A list of AI (or human) agents that participate in the group dialogue.\n",
    "- **Speaker Selection Method**: Determines which agent speaks next. Options include:\n",
    "  - `\"auto\"`: Uses the LLM to select the most contextually appropriate agent.\n",
    "  - `\"round_robin\"`: Agents take turns in a fixed sequence.\n",
    "  - `\"manual\"`: Human selects the next speaker.\n",
    "  - `\"random\"`: Agents are chosen randomly.\n",
    "\n",
    "This structure allows you to define collaborative workflows where agents build on each otherâ€™s contributions.\n",
    "\n",
    "### GroupChatManager\n",
    "\n",
    "`GroupChatManager` is responsible for managing the flow of the group conversation and it:\n",
    "\n",
    "- Orchestrates message passing between agents.\n",
    "- Decides when to stop the conversation (for example, based on a termination condition or turn limit).\n",
    "- Leverages the speaker selection method defined in `GroupChat`.\n",
    "\n",
    "It acts like a facilitator that ensures the conversation runs according to the logic you've configured.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. A conversation is initiated by one of the agents (often a user or teacher agent).\n",
    "2. The `GroupChatManager` uses the selected pattern (for example, AutoPattern) to determine which agent speaks next.\n",
    "3. Agents take turns responding based on their roles and system messages.\n",
    "4. The conversation ends either when a stop condition (for example, a message like \"DONE\") is met or when a maximum number of turns is reached.\n",
    "\n",
    "This setup enables modular, role-based collaboration â€” ideal for use cases like lesson planning, research workflows, or multi-perspective decision-making.\n",
    "\n",
    "To explore more orchestration patterns, visit the AG2 documentation at:  \n",
    "https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/orchestration/group-chat/introduction/\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Group Chat for Lesson Planning\n",
    "\n",
    "This example shows how a teacher agent collaborates with a planner and a reviewer to create a lesson plan, using AG2â€™s `GroupChat` and `AutoPattern` to manage the conversation.\n",
    "\n",
    "**Note:** The `is_termination_msg` parameter used for `teacher` agent defines a custom rule to end the conversation â€”  \n",
    "in this case, the workflow stops when the teacher replies with \"DONE!\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mteacher_agent\u001b[0m (to group_manager):\n",
      "\n",
      "Make a simple lesson about the moon.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/3329873030.py:11: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Next speaker: planner_agent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mplanner_agent\u001b[0m (to group_manager):\n",
      "\n",
      "### Lesson Plan: Exploring the Moon\n",
      "\n",
      "**Grade Level:** 4th Grade  \n",
      "**Subject:** Science  \n",
      "**Duration:** 1 Hour  \n",
      "\n",
      "---\n",
      "\n",
      "#### Lesson Objectives:\n",
      "- Students will learn about the Moon, its phases, and its importance to Earth.\n",
      "- Students will identify and describe the different phases of the Moon.\n",
      "- Students will understand the relationship between the Earth and the Moon.\n",
      "\n",
      "#### Materials Needed:\n",
      "- Whiteboard and markers\n",
      "- Moon Phase Chart (poster or handout)\n",
      "- Flashlight (to demonstrate moon phases)\n",
      "- Styrofoam balls (one per student or small groups)\n",
      "- Black construction paper\n",
      "- Scissors and glue\n",
      "- Access to a computer/tablet for research (if applicable)\n",
      "\n",
      "#### Lesson Outline:\n",
      "\n",
      "1. **Introduction (10 minutes)**  \n",
      "   - Begin with a question: â€œWhat do you know about the Moon?â€  \n",
      "   - Discuss responses and introduce key vocabulary (e.g., satellite, phases, orbit).\n",
      "\n",
      "2. **Direct Instruction (15 minutes)**  \n",
      "   - Explain what the Moon is and its relationship to Earth using the whiteboard.\n",
      "   - Introduce the phases of the Moon (new moon, crescent, first quarter, gibbous, full moon) using the Moon Phase Chart.\n",
      "   - Use the flashlight and Styrofoam balls to demonstrate how sunlight reflects off the Moon and creates different phases.  \n",
      "\n",
      "3. **Guided Activity (15 minutes)**  \n",
      "   - Have students work in pairs to create their own Moon Phase models using Styrofoam balls.   \n",
      "   - As they create, encourage them to discuss how the Moon changes shape and what causes these changes.  \n",
      "\n",
      "4. **Independent Activity (15 minutes)**  \n",
      "   - Distribute black construction paper and have students create a nighttime sky scene with the various moon phases they created.  \n",
      "   - Instruct students to label each phase with the correct name.  \n",
      "\n",
      "5. **Conclusion (5 minutes)**  \n",
      "   - Have a few students share their artwork and explain a phase of the Moon.  \n",
      "   - Summarize the key points discussed and emphasize the Moon's role in influencing tides on Earth.\n",
      "\n",
      "6. **Extension (optional)**  \n",
      "   - Assign a short research project where students can choose an aspect of the Moon to learn more about (e.g. its surface, exploration missions, myths and legends). They can present their findings in the next class.\n",
      "\n",
      "#### Assessment:\n",
      "- Observe participation in activities and discussions.\n",
      "- Review the completed Moon Phase models and artwork for understanding.\n",
      "- Optional: Short quiz on Moon phases and facts at the end of the week.\n",
      "\n",
      "---\n",
      "\n",
      "### Reflection:\n",
      "After the lesson, reflect on what worked well and what could be improved for future lessons. Consider student engagement and understanding of the phases of the Moon.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: reviewer_agent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mreviewer_agent\u001b[0m (to group_manager):\n",
      "\n",
      "This lesson plan on the Moon is well-structured and engaging for students. Here are three brief edits to enhance it:\n",
      "\n",
      "1. **Clarify Vocabulary Introduction**: Instead of introducing key vocabulary at the start of the lesson, consider embedding it throughout the lesson. For example, as you explain the phases of the Moon, introduce the terms in context when they first appear to enhance understanding.\n",
      "\n",
      "2. **Enhance Guided Activity Instructions**: Slightly expand the instructions for the guided activity to include a specific prompt for discussion among students. For instance, you could ask pairs to predict what the Moon will look like in a week and discuss their reasoning as they create their models.\n",
      "\n",
      "3. **Add Visual Engagement in Conclusion**: To make the conclusion more interactive, you could have a quick \"moon phase game\" where students are given the name of a phase and need to create the shape with their hands or the Styrofoam balls. This can reinforce the learning in a fun, engaging way.\n",
      "\n",
      "These edits aim to improve vocabulary integration, foster discussion among students, and enhance engagement at the conclusion.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: planner_agent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mplanner_agent\u001b[0m (to group_manager):\n",
      "\n",
      "Thank you for the valuable feedback! Hereâ€™s the revised lesson plan incorporating your suggestions:\n",
      "\n",
      "### Revised Lesson Plan: Exploring the Moon\n",
      "\n",
      "**Grade Level:** 4th Grade  \n",
      "**Subject:** Science  \n",
      "**Duration:** 1 Hour  \n",
      "\n",
      "---\n",
      "\n",
      "#### Lesson Objectives:\n",
      "- Students will learn about the Moon, its phases, and its importance to Earth.\n",
      "- Students will identify and describe the different phases of the Moon.\n",
      "- Students will understand the relationship between the Earth and the Moon.\n",
      "\n",
      "#### Materials Needed:\n",
      "- Whiteboard and markers\n",
      "- Moon Phase Chart (poster or handout)\n",
      "- Flashlight (to demonstrate moon phases)\n",
      "- Styrofoam balls (one per student or small groups)\n",
      "- Black construction paper\n",
      "- Scissors and glue\n",
      "- Access to a computer/tablet for research (if applicable)\n",
      "\n",
      "#### Lesson Outline:\n",
      "\n",
      "1. **Introduction (10 minutes)**  \n",
      "   - Begin with a question: â€œWhat do you know about the Moon?â€  \n",
      "   - Discuss responses and introduce key vocabulary (satellite, phases, orbit) as they are relevant throughout the lesson.\n",
      "\n",
      "2. **Direct Instruction (15 minutes)**  \n",
      "   - Explain what the Moon is and its relationship to Earth using the whiteboard.\n",
      "   - Introduce and explain the phases of the Moon (new moon, crescent, first quarter, gibbous, full moon) using the Moon Phase Chart. As each phase is introduced, incorporate the vocabulary naturally.\n",
      "\n",
      "3. **Guided Activity (15 minutes)**  \n",
      "   - Have students work in pairs to create their own Moon Phase models using Styrofoam balls.  \n",
      "   - Prompt pairs to predict what the Moon will look like in a week and discuss their reasoning as they create their models. Encourage a discussion on the cycle of moon phases as they work.\n",
      "\n",
      "4. **Independent Activity (15 minutes)**  \n",
      "   - Distribute black construction paper and have students create a nighttime sky scene with the various moon phases they created.  \n",
      "   - Instruct students to label each phase with the correct name.  \n",
      "\n",
      "5. **Conclusion (5 minutes)**  \n",
      "   - To reinforce learning, play a quick \"moon phase game\" where students are given the name of a phase, and they create the shape with their hands or the Styrofoam balls.\n",
      "   - Summarize the key points discussed and emphasize the Moon's role in influencing tides on Earth.\n",
      "\n",
      "6. **Extension (optional)**  \n",
      "   - Assign a short research project where students can choose an aspect of the Moon to learn more about (e.g. its surface, exploration missions, myths and legends). They can present their findings in the next class.\n",
      "\n",
      "#### Assessment:\n",
      "- Observe participation in activities and discussions.\n",
      "- Review the completed Moon Phase models and artwork for understanding.\n",
      "- Optional: Short quiz on Moon phases and facts at the end of the week.\n",
      "\n",
      "---\n",
      "\n",
      "### Reflection:\n",
      "After the lesson, reflect on what worked well and what could be improved for future lessons. Consider student engagement and understanding of the phases of the Moon.\n",
      "\n",
      "Thank you for your suggestions that have enhanced the clarity and engagement of this lesson plan!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_sync/connection.py:156\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 156\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_backends/sync.py:154\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m    150\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    151\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    153\u001b[0m }\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m manager \u001b[38;5;241m=\u001b[39m GroupChatManager(\n\u001b[1;32m     37\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     groupchat\u001b[38;5;241m=\u001b[39mgroupchat,\n\u001b[1;32m     39\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Start with a short initial prompt to keep tokens low\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mteacher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMake a simple lesson about the moon.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limit total rounds (e.g., 2 per agent max) -  As a safeguard, it's always best to use max_turns to prevent runaway loops.\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1460\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1460\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# No breaks in the for loop, so we have reached max turns\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     iostream\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1463\u001b[0m         TerminationEvent(\n\u001b[1;32m   1464\u001b[0m             termination_reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum turns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_turns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) reached\u001b[39m\u001b[38;5;124m\"\u001b[39m, sender\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, recipient\u001b[38;5;241m=\u001b[39mrecipient\n\u001b[1;32m   1465\u001b[0m         )\n\u001b[1;32m   1466\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1126\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m   1124\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, recipient, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1130\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1234\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2881\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2881\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2883\u001b[0m         log_event(\n\u001b[1;32m   2884\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2885\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2890\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:1255\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[43mgroupchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[1;32m   1257\u001b[0m         iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:581\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[0;34m(self, last_speaker, selector)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_agent(last_speaker)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:762\u001b[0m, in \u001b[0;36mGroupChat._auto_select_speaker\u001b[0;34m(self, last_speaker, selector, messages, agents)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_speaker_selection_transforms\u001b[38;5;241m.\u001b[39madd_to_agent(speaker_selection_agent)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# Run the speaker selection chat\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchecking_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_selection_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# don't use caching for the speaker selection chat\u001b[39;49;00m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limiting the chat to the number of attempts, including the initial one\u001b[39;49;00m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker_auto_verbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Base silence on the verbose attribute\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_speaker_selection_result(result, last_speaker, agents)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1460\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg2send \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1460\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# No breaks in the for loop, so we have reached max turns\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     iostream\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1463\u001b[0m         TerminationEvent(\n\u001b[1;32m   1464\u001b[0m             termination_reason\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum turns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_turns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) reached\u001b[39m\u001b[38;5;124m\"\u001b[39m, sender\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, recipient\u001b[38;5;241m=\u001b[39mrecipient\n\u001b[1;32m   1465\u001b[0m         )\n\u001b[1;32m   1466\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1126\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m   1124\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, recipient, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1130\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1234\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2881\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m   2879\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2881\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2883\u001b[0m         log_event(\n\u001b[1;32m   2884\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2885\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2889\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2890\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2162\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config, **kwargs)\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM call blocked by safeguard\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m-> 2162\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;66;03m# Process LLM response\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2197\u001b[0m, in \u001b[0;36mConversableAgent._generate_oai_reply_from_client\u001b[0;34m(self, llm_client, messages, cache, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         all_messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[1;32m   2196\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m-> 2197\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2204\u001b[0m extracted_response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mextract_text_or_completion_object(response)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extracted_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:1263\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[0;34m(self, **config)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     request_ts \u001b[38;5;241m=\u001b[39m get_current_ts()\n\u001b[0;32m-> 1263\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m openai_result\u001b[38;5;241m.\u001b[39mis_successful:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:684\u001b[0m, in \u001b[0;36mOpenAIClient.create\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_reasoning_model_params(params)\n\u001b[1;32m    683\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_or_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# remove the system_message from the response and add it in the prompt at the start.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_o1:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/autogen/oai/client.py:455\u001b[0m, in \u001b[0;36mOpenAIClient._handle_openai_bad_request_error.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m OpenAIClient\u001b[38;5;241m.\u001b[39m_patch_messages_for_deepseek_reasoner(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    457\u001b[0m     response_json \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/_base_client.py:1014\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent, GroupChat, GroupChatManager, LLMConfig\n",
    "\n",
    "# Replace \"PLACEHOLDER\" with your actual OpenAI API key if running locally\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\", )  # add api_key=\"PLACE_HOLDER\" Replace with your API key to run outside this learning environment\n",
    "\n",
    "# Define system messages and agent descriptions\n",
    "planner_message = \"Create a short lesson plan for 4th graders.\"\n",
    "reviewer_message = \"Review a plan and suggest up to 3 brief edits.\"\n",
    "teacher_message = \"Suggest a topic and reply DONE when satisfied.\"\n",
    "\n",
    "with llm_config:\n",
    "    lesson_planner = ConversableAgent(\n",
    "        name=\"planner_agent\",\n",
    "        system_message=planner_message,\n",
    "        description=\"Makes lesson plans.\",\n",
    "    )\n",
    "\n",
    "    lesson_reviewer = ConversableAgent(\n",
    "        name=\"reviewer_agent\",\n",
    "        system_message=reviewer_message,\n",
    "        description=\"Reviews lesson plans and suggests edits.\",\n",
    "    )\n",
    "\n",
    "    teacher = ConversableAgent(\n",
    "        name=\"teacher_agent\",\n",
    "        system_message=teacher_message,\n",
    "        is_termination_msg=lambda x: \"DONE\" in (x.get(\"content\", \"\") or \"\").upper()\n",
    "    )\n",
    "\n",
    "# Configure the group chat with automatic speaker selection\n",
    "groupchat = GroupChat(\n",
    "    agents=[teacher, lesson_planner, lesson_reviewer],\n",
    "    speaker_selection_method=\"auto\"  # Uses AutoPattern\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(\n",
    "    name=\"group_manager\",\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "# Start with a short initial prompt to keep tokens low\n",
    "teacher.initiate_chat(\n",
    "    recipient=manager,\n",
    "    message=\"Make a simple lesson about the moon.\",\n",
    "    max_turns=3,  # Limit total rounds (e.g., 2 per agent max) -  As a safeguard, it's always best to use max_turns to prevent runaway loops.\n",
    "    summary_method=\"reflection_with_llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and Extensions<a name=\"tools\"></a>\n",
    "\n",
    "Tools extend agent capabilities beyond text conversations, allowing them to:\n",
    "- Execute code\n",
    "- Access external APIs\n",
    "- Perform calculations\n",
    "- Interact with databases\n",
    "- Generate visualizations\n",
    "\n",
    "Agents gain significant utility through tools as they provide access to external data, APIs, and functionality.  \n",
    "\n",
    "Let's explore how to integrate tools with AG2 agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmath_checker\u001b[0m (to math_asker):\n",
      "\n",
      "Is 72 a prime number?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/2985873808.py:17: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmath_asker\u001b[0m (to math_checker):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_zlL1YUTkm35Nh8ulS8hw67aG): is_prime *****\u001b[0m\n",
      "Arguments: \n",
      "{\"n\":72}\n",
      "\u001b[32m*************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION is_prime...\n",
      "Call ID: call_zlL1YUTkm35Nh8ulS8hw67aG\n",
      "Input arguments: {'n': 72}\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTED FUNCTION is_prime...\n",
      "Call ID: call_zlL1YUTkm35Nh8ulS8hw67aG\n",
      "Input arguments: {'n': 72}\n",
      "Output:\n",
      "No\u001b[0m\n",
      "\u001b[33mmath_checker\u001b[0m (to math_asker):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_zlL1YUTkm35Nh8ulS8hw67aG) *****\u001b[0m\n",
      "No\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mmath_asker\u001b[0m (to math_checker):\n",
      "\n",
      "No, 72 is not a prime number.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (1ff14561-1d7b-4374-82a8-10c316237706): Maximum turns (2) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=140315229002311343896180925709349445068, chat_history=[{'content': 'Is 72 a prime number?', 'role': 'assistant', 'name': 'math_checker'}, {'tool_calls': [{'id': 'call_zlL1YUTkm35Nh8ulS8hw67aG', 'function': {'arguments': '{\"n\":72}', 'name': 'is_prime'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}, {'content': 'No', 'tool_responses': [{'tool_call_id': 'call_zlL1YUTkm35Nh8ulS8hw67aG', 'role': 'tool', 'content': 'No'}], 'role': 'tool', 'name': 'math_checker'}, {'content': 'No, 72 is not a prime number.', 'role': 'user', 'name': 'math_asker'}], summary='No, 72 is not a prime number.', cost={'usage_including_cached_inference': {'total_cost': 3.945e-05, 'gpt-4o-mini-2024-07-18': {'cost': 3.945e-05, 'prompt_tokens': 163, 'completion_tokens': 25, 'total_tokens': 188}}, 'usage_excluding_cached_inference': {'total_cost': 3.945e-05, 'gpt-4o-mini-2024-07-18': {'cost': 3.945e-05, 'prompt_tokens': 163, 'completion_tokens': 25, 'total_tokens': 188}}}, human_input=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen import ConversableAgent, register_function, LLMConfig\n",
    "from typing import Annotated\n",
    "\n",
    "# Replace with your actual key if running outside this environment\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define a simple utility function to check if a number is prime\n",
    "def is_prime(n: Annotated[int, \"Positive integer\"]) -> str:\n",
    "    if n < 2:\n",
    "        return \"No\"\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "# Create the asking agent and the tool-using agent\n",
    "with llm_config:\n",
    "    math_asker = ConversableAgent(\n",
    "        name=\"math_asker\",\n",
    "        system_message=\"Ask whether a number is prime.\"\n",
    "    )\n",
    "    math_checker = ConversableAgent(\n",
    "        name=\"math_checker\",\n",
    "        human_input_mode=\"NEVER\"\n",
    "    )\n",
    "\n",
    "# Register the function between the two agents\n",
    "register_function(\n",
    "    is_prime,\n",
    "    caller=math_asker,\n",
    "    executor=math_checker,\n",
    "    description=\"Check if a number is prime. Returns Yes or No.\"\n",
    ")\n",
    "\n",
    "# Start a brief conversation\n",
    "math_checker.initiate_chat(\n",
    "    recipient=math_asker,\n",
    "    message=\"Is 72 a prime number?\",\n",
    "    max_turns=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is `register_function(...)` ?\n",
    "\n",
    "In AG2, `register_function(...)` is used to expose a Python function as a **tool** that can be executed by one agent on behalf of another. This enables agents to delegate tasks like computation, data processing, or external API calls.\n",
    "\n",
    "#### Purpose\n",
    "- Extend agent capabilities beyond text generation.\n",
    "- Allow agents to solve tasks through **function execution**.\n",
    "- Enable collaborative workflows between a **caller** and an **executor** agent.\n",
    "\n",
    "#### Parameters\n",
    "- **function**: A regular Python function to be used as a tool.\n",
    "- **caller**: The agent that will request the tool to be used.\n",
    "- **executor**: The agent that will actually execute the function.\n",
    "- **description** *(optional)*: A natural language description of the function for the LLM to decide when to use it.\n",
    "\n",
    "#### Example\n",
    "```python\n",
    "register_function(\n",
    "    is_prime,\n",
    "    caller=math_asker,\n",
    "    executor=math_checker,\n",
    "    description=\"Check if a number is prime. Returns Yes or No.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Outputs<a name=\"structured-outputs\"></a>\n",
    "\n",
    "Structured outputs ensure consistent, validated agent responses using Pydantic models.   \n",
    "\n",
    "This is crucial for:\n",
    "  \n",
    "- **Data validation**: Ensuring response format consistency\n",
    "- **API integration**: Reliable data exchange\n",
    "- **Quality assurance**: Preventing malformed outputs\n",
    "- **Type safety**: Clear data contracts\n",
    "\n",
    "**Analogy:** Like standardized hospital forms ensure doctors always record patient info the same way, structured outputs make sure agents respond in predictable, machine-readable formats.\n",
    "\n",
    "\n",
    "In AG2, structured outputs are implemented using Pydantic models and the `response_format` parameter in the `LLMConfig`.\n",
    "\n",
    "To ensure that your agent always returns outputs in a consistent structure, you define a Pydantic class (for example, `ResponseModel`) and assign it to the `response_format` argument of your configuration.\n",
    "\n",
    "This tells the underlying LLM to return a JSON-compatible response matching the defined schema.\n",
    "\n",
    "```python\n",
    "class ResponseModel(BaseModel):\n",
    "    name: str\n",
    "    status: str\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=ResponseModel\n",
    ")\n",
    "```\n",
    "\n",
    "With this setup:\n",
    "\n",
    "- The agent automatically formats its responses to match the ResponseModel. \n",
    "- You donâ€™t need to prompt the LLM to format its response.\n",
    "- The response is parsed and validated by AG2.\n",
    "\n",
    "This approach is essential for reliable automation, integrations, and downstream processing.\n",
    "\n",
    "Let's implement structured outputs with AG2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33msupport_agent\u001b[0m (to support_agent):\n",
      "\n",
      "Ticket: John Doe is unable to reset his password and has an important meeting in 30 minutes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300/2146761788.py:19: DeprecationWarning: `with llm_config: ...` context manager is deprecated. Pass config object to usage explicitly instead. Scheduled for removal in 0.11.0 version.\n",
      "  with llm_config:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33msupport_agent\u001b[0m (to support_agent):\n",
      "\n",
      "{\"customer_name\":\"John Doe\",\"issue_type\":\"login issue\",\"urgency_level\":\"High\",\"recommended_action\":\"Assist John with password reset immediately to ensure he can access his account before the meeting.\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (5ee59f44-8e83-4f18-bbe1-f59dfd1b4dd1): Maximum turns (1) reached\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=251696044307258726979203745434581865407, chat_history=[{'content': 'Ticket: John Doe is unable to reset his password and has an important meeting in 30 minutes.', 'role': 'assistant', 'name': 'support_agent'}, {'content': 'Ticket: John Doe is unable to reset his password and has an important meeting in 30 minutes.', 'role': 'user', 'name': 'support_agent'}, {'content': '{\"customer_name\":\"John Doe\",\"issue_type\":\"login issue\",\"urgency_level\":\"High\",\"recommended_action\":\"Assist John with password reset immediately to ensure he can access his account before the meeting.\"}', 'role': 'assistant', 'name': 'support_agent'}, {'content': '{\"customer_name\":\"John Doe\",\"issue_type\":\"login issue\",\"urgency_level\":\"High\",\"recommended_action\":\"Assist John with password reset immediately to ensure he can access his account before the meeting.\"}', 'role': 'user', 'name': 'support_agent'}], summary='{\"customer_name\":\"John Doe\",\"issue_type\":\"login issue\",\"urgency_level\":\"High\",\"recommended_action\":\"Assist John with password reset immediately to ensure he can access his account before the meeting.\"}', cost={'usage_including_cached_inference': {'total_cost': 0.00010529999999999998, 'gpt-4o-mini-2024-07-18': {'cost': 0.00010529999999999998, 'prompt_tokens': 382, 'completion_tokens': 80, 'total_tokens': 462}}, 'usage_excluding_cached_inference': {'total_cost': 0.00010529999999999998, 'gpt-4o-mini-2024-07-18': {'cost': 0.00010529999999999998, 'prompt_tokens': 382, 'completion_tokens': 80, 'total_tokens': 462}}}, human_input=[])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "# Define the structure of the agent's output\n",
    "class TicketSummary(BaseModel):\n",
    "    customer_name: str\n",
    "    issue_type: str\n",
    "    urgency_level: str\n",
    "    recommended_action: str\n",
    "\n",
    "# Configure the LLM with the structured output format\n",
    "llm_config = LLMConfig(\n",
    "    api_type=\"openai\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=TicketSummary,\n",
    ")\n",
    "\n",
    "# Create the agent\n",
    "with llm_config:\n",
    "    support_agent = ConversableAgent(\n",
    "        name=\"support_agent\",\n",
    "        system_message=(\n",
    "            \"You are a support assistant. Summarize a customer ticket using:\"\n",
    "            \"\\n- customer_name\"\n",
    "            \"\\n- issue_type (e.g. login issue, billing problem, bug report)\"\n",
    "            \"\\n- urgency_level (Low, Medium, High)\"\n",
    "            \"\\n- recommended_action\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Start a structured conversation\n",
    "support_agent.initiate_chat(\n",
    "    recipient=support_agent,\n",
    "    message=\"Ticket: John Doe is unable to reset his password and has an important meeting in 30 minutes.\",\n",
    "    max_turns=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices<a name=\"best-practices\"></a>\n",
    "\n",
    "Based on our exploration of AG2 concepts, here are key best practices for building robust agent systems:\n",
    "\n",
    "### Configuration and security\n",
    "- **Never hardcode API keys** - use environment variables\n",
    "- **Use config lists** for production systems with fallback models\n",
    "- **Set appropriate temperature** values (0.0 for deterministic, 0.7-1.0 for creative)\n",
    "- **Implement rate limiting** and error handling\n",
    "\n",
    "### Agent design\n",
    "- **Write clear system messages** that define role, capabilities, and constraints\n",
    "- **Set max_consecutive_auto_reply** to prevent infinite loops\n",
    "- **Choose appropriate human_input_mode** based on use case\n",
    "- **Specialize agents** for specific tasks rather than creating generalists\n",
    "\n",
    "### HITL implementation\n",
    "- **Use HITL for high-stakes decisions** requiring human judgment\n",
    "- **Implement clear escalation criteria** (amount thresholds, risk levels)\n",
    "- **Provide context** to human supervisors for informed decisions\n",
    "- **Log all human interventions** for audit trails\n",
    "\n",
    "### Multi-agent orchestration\n",
    "- **Design clear workflows** with defined handoffs between agents\n",
    "- **Use GroupChat** for collaborative problem-solving\n",
    "- **Implement termination conditions** to prevent endless conversations\n",
    "- **Monitor conversation quality** and intervention points\n",
    "\n",
    "### Tools and integration\n",
    "- **Create focused tools** for specific capabilities\n",
    "- **Implement proper error handling** in tool functions\n",
    "- **Validate tool inputs** and outputs\n",
    "- **Document tool capabilities** clearly for agents\n",
    "\n",
    "### Structured outputs\n",
    "- **Use Pydantic models** for data validation\n",
    "- **Define clear schemas** for consistent outputs\n",
    "- **Implement proper validation** with meaningful error messages\n",
    "- **Version your schemas** for backward compatibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion<a name=\"conclusion\"></a>\n",
    "\n",
    "Congratulations! You've completed a comprehensive tour of AG2's basic concepts. Let's recap what we've learned:\n",
    "\n",
    "### Key concepts mastered:\n",
    "\n",
    "- **LLM Configuration** - The foundation that connects agents to language models\n",
    "- **ConversableAgent** - The core building block for all AG2 agents\n",
    "- **Human in the Loop (HITL)** - Enabling human oversight in AI workflows\n",
    "- **Agent Orchestration** - Coordinating multiple agents for complex tasks\n",
    "- **Tools & Extensions** - Extending agent capabilities beyond text\n",
    "- **Structured Outputs** - Ensuring consistent, validated responses\n",
    "\n",
    "### Practical skills developed:\n",
    "\n",
    "- Creating and configuring specialized agents\n",
    "- Implementing multi-agent collaboration patterns\n",
    "- Building HITL workflows for critical decisions\n",
    "- Integrating tools and external capabilities\n",
    "- Validating outputs with structured schemas\n",
    "- Following security and operational best practices\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "Now that you understand AG2's basic concepts, you can:\n",
    "\n",
    "1. **Build Domain-Specific Applications** - Apply these concepts to your specific use case.\n",
    "2. **Explore Advanced Features** - Dive into code execution, web scraping, and API integrations.\n",
    "3. **Scale Your Systems** - Learn about production deployment and monitoring.\n",
    "4. **Join the Community** - Contribute to the AG2 ecosystem and learn from others.\n",
    "\n",
    "### Things to remember:\n",
    "\n",
    "- **Start simple** and gradually add complexity.\n",
    "- **Test thoroughly** with various scenarios.\n",
    "- **Monitor performance** and adjust configurations.\n",
    "- **Follow best practices** for security and reliability.\n",
    "- **Keep learning** as AG2 continues to evolve.\n",
    "\n",
    "AG2 provides a powerful foundation for building intelligent, collaborative AI systems. The concepts you've learned here will serve as building blocks for more advanced implementations.  \n",
    "\n",
    "### Advanced agentic design patterns:  \n",
    "  \n",
    "AG2 supports advanced features like custom rules for conversation endings, RAG, code execution, and secure tool use. You can learn more from the official documentation.  \n",
    "  \n",
    "Happy building with AG2! ðŸ¤–âœ¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Faranak Heidari](https://www.linkedin.com/in/faranakhdr/) is a Data Scientist and AI developr at IBM with expertise in GenAI, machine learning, and data analytics. Experienced in building LLMs, forecasting models, and scalable ML pipelines for domains like healthcare. Passionate about driving innovation and collaborating with teams to integrate AI into real-world workflows.\n",
    "\n",
    "[Joshua Zhou](https://www.linkedin.com/in/joshuazhou1/) is a Data Scientist Intern at IBM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "<details>\n",
    "    <summary>Click here for the changelog</summary>\n",
    "\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2025-07-17|0.1|Faranak Heidari|Initial version created|\n",
    "|2025-07-27|0.2|Steve Ryan|ID review and format fixes|\n",
    "|2025-07-28|0.3|Mercedes Schneider|QA pass with edits|\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Copyright Â© IBM Corporation. All rights reserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "17556ac98af6ba46cf3370eae526d0c678ae2e3c89216563a6c4eaec56777c60"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
