{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e38cf46-766d-4fc5-b843-41d3f97cd73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb==1.0.12\n",
      "  Downloading chromadb-1.0.12-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==1.0.12)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (2.8.2)\n",
      "Collecting fastapi==0.115.9 (from chromadb==1.0.12)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==1.0.12)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb==1.0.12)\n",
      "  Downloading posthog-6.8.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==1.0.12)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==1.0.12)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==1.0.12)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==1.0.12)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==1.0.12)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==1.0.12)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==1.0.12)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb==1.0.12)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==1.0.12)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==1.0.12)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==1.0.12)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==1.0.12)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb==1.0.12)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from chromadb==1.0.12) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb==1.0.12)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb==1.0.12) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==1.0.12)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb==1.0.12) (0.4.6)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb==1.0.12)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.0.12) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.0.12) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.0.12) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.0.12) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.0.12) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.0.12) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.0.12) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.0.12) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.0.12) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.0.12) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.0.12) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.0.12) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading google_auth-2.42.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.0.12) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.0.12) (2.32.5)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==1.0.12)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==1.0.12)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.0.12) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.0.12) (1.13.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==1.0.12) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.12)\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==1.0.12)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.59b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12)\n",
      "  Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.59b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==1.0.12)\n",
      "  Downloading asgiref-3.10.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==1.0.12)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb==1.0.12) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb==1.0.12) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb==1.0.12) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb==1.0.12) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb==1.0.12) (2.15.1)\n",
      "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb==1.0.12)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb==1.0.12) (8.1.7)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==1.0.12)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.12) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==1.0.12)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.12) (15.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.12) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.12) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.12) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.12) (2024.6.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.12) (1.5.0)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.12)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.12)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.0.12) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.0.12) (0.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb==1.0.12) (3.3.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.0.12)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.0.12)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.0.12) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==1.0.12)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.12) (0.4.8)\n",
      "Downloading chromadb-1.0.12-cp39-abi3-win_amd64.whl (19.3 MB)\n",
      "   ---------------------------------------- 0.0/19.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/19.3 MB 5.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.3/19.3 MB 2.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.1/19.3 MB 3.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.4/19.3 MB 2.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.1/19.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.1/19.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.1/19.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.1/19.3 MB 3.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.9/19.3 MB 2.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 4.2/19.3 MB 2.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 4.2/19.3 MB 2.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 4.2/19.3 MB 2.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 4.2/19.3 MB 2.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 4.7/19.3 MB 1.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 5.2/19.3 MB 1.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 6.3/19.3 MB 1.8 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 6.3/19.3 MB 1.8 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 7.3/19.3 MB 1.9 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 7.9/19.3 MB 1.4 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 8.9/19.3 MB 1.5 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 9.4/19.3 MB 1.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 10.0/19.3 MB 1.6 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 10.7/19.3 MB 1.7 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 11.5/19.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 11.5/19.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 11.5/19.3 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 11.8/19.3 MB 1.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 12.6/19.3 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 12.6/19.3 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 12.6/19.3 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 12.6/19.3 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 13.6/19.3 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 14.7/19.3 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 15.2/19.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 16.0/19.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 17.0/19.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 17.8/19.3 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.4/19.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/19.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/19.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/19.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.3/19.3 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.1/4.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.0/2.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/13.5 MB 5.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.1/13.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/13.5 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.5/13.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.6/13.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.6/13.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.7/13.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.7/13.5 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.0/13.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.1/13.5 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl (13 kB)\n",
      "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl (7.6 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading posthog-6.8.0-py3-none-any.whl (141 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.42.1-py2.py3-none-any.whl (222 kB)\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading huggingface_hub-1.0.1-py3-none-any.whl (503 kB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl (288 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.10.0-py3-none-any.whl (24 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/2.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=7f051dde4b4d2b500309ed8d03621b6e0a0c8b4adb82fbbbe50b9fb1088aaa0b\n",
      "  Stored in directory: c:\\users\\mukes\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, urllib3, typing-extensions, rsa, pyreadline3, pyproject_hooks, protobuf, orjson, opentelemetry-util-http, oauthlib, mmh3, importlib-resources, httptools, hf-xet, bcrypt, backoff, asgiref, watchfiles, uvicorn, typer-slim, starlette, opentelemetry-proto, opentelemetry-api, humanfriendly, grpcio, googleapis-common-protos, google-auth, build, requests-oauthlib, posthog, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, huggingface-hub, coloredlogs, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.10.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.0.12 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.115.9 flatbuffers-25.9.23 google-auth-2.42.1 googleapis-common-protos-1.71.0 grpcio-1.76.0 hf-xet-1.2.0 httptools-0.7.1 huggingface-hub-1.0.1 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-34.1.0 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-asgi-0.59b0 opentelemetry-instrumentation-fastapi-0.59b0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-util-http-0.59b0 orjson-3.11.4 posthog-6.8.0 protobuf-6.33.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rsa-4.9.1 starlette-0.45.3 tokenizers-0.22.1 typer-slim-0.20.0 typing-extensions-4.15.0 urllib3-2.3.0 uvicorn-0.38.0 watchfiles-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibm-cos-sdk-core 2.14.3 requires urllib3<3,>=2.5.0, but you have urllib3 2.3.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers==4.1.0\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers==4.1.0)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers==4.1.0)\n",
      "  Downloading torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (1.0.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sentence-transformers==4.1.0) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (2024.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (6.0.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (0.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (1.2.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers==4.1.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers==4.1.0) (0.4.6)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers==4.1.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (0.22.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==4.1.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==4.1.0) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==4.1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers==4.1.0) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers==4.1.0) (2025.10.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mukes\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers==4.1.0) (8.1.7)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/109.3 MB 5.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.4/109.3 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 3.4/109.3 MB 5.6 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.5/109.3 MB 5.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 5.8/109.3 MB 5.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 6.8/109.3 MB 5.4 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 7.9/109.3 MB 5.4 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 9.2/109.3 MB 5.4 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 10.2/109.3 MB 5.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 11.3/109.3 MB 5.4 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 12.3/109.3 MB 5.4 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 13.6/109.3 MB 5.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 14.7/109.3 MB 5.5 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 16.0/109.3 MB 5.5 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 17.0/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 18.1/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 19.4/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 20.4/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 21.5/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 22.5/109.3 MB 5.4 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 23.6/109.3 MB 5.4 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 24.9/109.3 MB 5.4 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 26.0/109.3 MB 5.4 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 27.3/109.3 MB 5.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 28.6/109.3 MB 5.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 29.6/109.3 MB 5.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 30.7/109.3 MB 5.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 32.0/109.3 MB 5.5 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 33.0/109.3 MB 5.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 34.3/109.3 MB 5.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 35.4/109.3 MB 5.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 36.7/109.3 MB 5.5 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 37.7/109.3 MB 5.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 38.8/109.3 MB 5.5 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 40.1/109.3 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 41.2/109.3 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 42.2/109.3 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 43.5/109.3 MB 5.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 44.6/109.3 MB 5.5 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 45.6/109.3 MB 5.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 46.9/109.3 MB 5.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 48.0/109.3 MB 5.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 5.5 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 50.3/109.3 MB 5.5 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 51.4/109.3 MB 5.5 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 52.7/109.3 MB 5.5 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 53.7/109.3 MB 5.5 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 54.8/109.3 MB 5.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 56.1/109.3 MB 5.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 57.1/109.3 MB 5.5 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 58.2/109.3 MB 5.5 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 59.5/109.3 MB 5.5 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 60.6/109.3 MB 5.5 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 61.9/109.3 MB 5.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 5.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 64.2/109.3 MB 5.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 65.3/109.3 MB 5.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 66.3/109.3 MB 5.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 67.4/109.3 MB 5.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 68.7/109.3 MB 5.5 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 70.0/109.3 MB 5.5 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 71.0/109.3 MB 5.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 72.1/109.3 MB 5.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 73.1/109.3 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 74.4/109.3 MB 5.5 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 75.8/109.3 MB 5.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 76.8/109.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 79.2/109.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 80.5/109.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 81.5/109.3 MB 5.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 82.8/109.3 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 83.9/109.3 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 84.9/109.3 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 86.2/109.3 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 87.3/109.3 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 88.6/109.3 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 89.7/109.3 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 91.0/109.3 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 91.8/109.3 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 93.1/109.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 94.1/109.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 95.4/109.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 96.5/109.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 97.5/109.3 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 98.8/109.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 99.9/109.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 100.9/109.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 102.2/109.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.5/109.3 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 104.6/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 105.6/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.0/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.0/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.3/109.3 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/12.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/12.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.2/12.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, safetensors, torch, huggingface-hub, transformers, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 1.0.1\n",
      "    Uninstalling huggingface-hub-1.0.1:\n",
      "      Successfully uninstalled huggingface-hub-1.0.1\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.6.2 sentence-transformers-4.1.0 sympy-1.14.0 torch-2.9.0 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb==1.0.12\n",
    "!pip install sentence-transformers==4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa5d627-4f80-4752-b1f8-73ab3634a32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa47649f135452fbe31f48018a7041f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukes\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mukes\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5352af8620d740ddbfc6e8067a8caa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3eaf6d353174c30856a5956d35a1d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d07339e4d104cab8104221849324924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a27fc76ad04a7380da9231da5230d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeb11ee69824cf38d730409861b23c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc6cbf796f9486e9f4c14636c199500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09745afe7a544fea90145d7d62ff090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f740e81b284a158b974bab396068d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6021ff85854d4ea03eaef23b4775d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5871fc3c9aea42e999a4a534b2e6364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created: employee_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection contents:\n",
      "Number of documents: 15\n",
      "=== Similarity Search Examples ===\n",
      "\n",
      "1. Searching for Python developers:\n",
      "Query: 'Python developer with web development experience'\n",
      "  1. John Doe (employee_1) - Distance: 0.5156\n",
      "     Role: Software Engineer, Department: Engineering\n",
      "     Document: Software Engineer with 5 years of experience in Engineering. Skills: Python, JavaScript, React, Node...\n",
      "  2. Matthew Garcia (employee_14) - Distance: 0.5724\n",
      "     Role: Junior Software Engineer, Department: Engineering\n",
      "     Document: Junior Software Engineer with 3 years of experience in Engineering. Skills: JavaScript, HTML/CSS, ba...\n",
      "  3. Alex Rodriguez (employee_10) - Distance: 0.5967\n",
      "     Role: Lead Software Engineer, Department: Engineering\n",
      "     Document: Lead Software Engineer with 18 years of experience in Engineering. Skills: Full-stack development, R...\n",
      "\n",
      "2. Searching for leadership and management roles:\n",
      "Query: 'team leader manager with experience'\n",
      "  1. Jane Smith (employee_2) - Distance: 0.5382\n",
      "     Role: Marketing Manager, Experience: 8 years\n",
      "  2. Sarah Clark (employee_7) - Distance: 0.5467\n",
      "     Role: HR Manager, Experience: 8 years\n",
      "  3. David Lee (employee_6) - Distance: 0.5497\n",
      "     Role: Engineering Manager, Experience: 15 years\n",
      "\n",
      "=== Metadata Filtering Examples ===\n",
      "\n",
      "3. Finding all Engineering employees:\n",
      "Found 8 Engineering employees:\n",
      "  - John Doe: Software Engineer (5 years)\n",
      "  - Michael Brown: Senior Software Engineer (12 years)\n",
      "  - David Lee: Engineering Manager (15 years)\n",
      "  - Chris Evans: Senior Architect (20 years)\n",
      "  - Alex Rodriguez: Lead Software Engineer (18 years)\n",
      "  - Kevin Martinez: DevOps Engineer (10 years)\n",
      "  - Matthew Garcia: Junior Software Engineer (3 years)\n",
      "  - Olivia Moore: Principal Engineer (12 years)\n",
      "\n",
      "4. Finding employees with 10+ years experience:\n",
      "Found 6 senior employees:\n",
      "  - Michael Brown: Senior Software Engineer (12 years)\n",
      "  - David Lee: Engineering Manager (15 years)\n",
      "  - Chris Evans: Senior Architect (20 years)\n",
      "  - Alex Rodriguez: Lead Software Engineer (18 years)\n",
      "  - Kevin Martinez: DevOps Engineer (10 years)\n",
      "  - Olivia Moore: Principal Engineer (12 years)\n",
      "\n",
      "5. Finding employees in California:\n",
      "Found 3 employees in California:\n",
      "  - Jane Smith: Los Angeles\n",
      "  - Michael Brown: San Francisco\n",
      "  - Olivia Moore: San Francisco\n",
      "\n",
      "=== Combined Search: Similarity + Metadata Filtering ===\n",
      "\n",
      "6. Finding senior Python developers in major tech cities:\n",
      "Query: 'senior Python developer full-stack' with filters (8+ years, major tech cities)\n",
      "Found 4 matching employees:\n",
      "  1. Michael Brown (employee_4) - Distance: 0.6726\n",
      "     Senior Software Engineer in San Francisco (12 years)\n",
      "     Document snippet: Senior Software Engineer with 12 years of experience in Engineering. Skills: Jav...\n",
      "  2. Chris Evans (employee_8) - Distance: 0.7537\n",
      "     Senior Architect in New York (20 years)\n",
      "     Document snippet: Senior Architect with 20 years of experience in Engineering. Skills: System desi...\n",
      "  3. David Lee (employee_6) - Distance: 0.8344\n",
      "     Engineering Manager in Seattle (15 years)\n",
      "     Document snippet: Engineering Manager with 15 years of experience in Engineering. Skills: Team lea...\n",
      "  4. Olivia Moore (employee_15) - Distance: 0.8761\n",
      "     Principal Engineer in San Francisco (12 years)\n",
      "     Document snippet: Principal Engineer with 12 years of experience in Engineering. Skills: Technical...\n",
      "Top 3 similar documents to \"senior Python developer full-stack\":\n",
      " - ID: employee_4, Text: \"Senior Software Engineer with 12 years of experience in Engineering. Skills: Java, Spring Boot, microservices, cloud architecture, DevOps. Located in San Francisco. Employment type: Full-time.\", Score: 0.6726\n",
      " - ID: employee_8, Text: \"Senior Architect with 20 years of experience in Engineering. Skills: System design, distributed systems, cloud platforms, technical strategy. Located in New York. Employment type: Full-time.\", Score: 0.7537\n",
      " - ID: employee_6, Text: \"Engineering Manager with 15 years of experience in Engineering. Skills: Team leadership, project management, software architecture, mentoring. Located in Seattle. Employment type: Full-time.\", Score: 0.8344\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_name = \"employee_collection\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"A collection for storing employee data\"},\n",
    "            configuration={\n",
    "                \"hnsw\": {\"space\": \"cosine\"},\n",
    "                \"embedding_function\": ef\n",
    "            }\n",
    "        )\n",
    "        print(f\"Collection created: {collection.name}\")\n",
    "\n",
    "        employees = [\n",
    "            {\"id\": \"employee_1\", \"name\": \"John Doe\", \"experience\": 5, \"department\": \"Engineering\", \"role\": \"Software Engineer\", \"skills\": \"Python, JavaScript, React, Node.js, databases\", \"location\": \"New York\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_2\", \"name\": \"Jane Smith\", \"experience\": 8, \"department\": \"Marketing\", \"role\": \"Marketing Manager\", \"skills\": \"Digital marketing, SEO, content strategy, analytics, social media\", \"location\": \"Los Angeles\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_3\", \"name\": \"Alice Johnson\", \"experience\": 3, \"department\": \"HR\", \"role\": \"HR Coordinator\", \"skills\": \"Recruitment, employee relations, HR policies, training programs\", \"location\": \"Chicago\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_4\", \"name\": \"Michael Brown\", \"experience\": 12, \"department\": \"Engineering\", \"role\": \"Senior Software Engineer\", \"skills\": \"Java, Spring Boot, microservices, cloud architecture, DevOps\", \"location\": \"San Francisco\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_5\", \"name\": \"Emily Wilson\", \"experience\": 2, \"department\": \"Marketing\", \"role\": \"Marketing Assistant\", \"skills\": \"Content creation, email marketing, market research, social media management\", \"location\": \"Austin\", \"employment_type\": \"Part-time\"},\n",
    "            {\"id\": \"employee_6\", \"name\": \"David Lee\", \"experience\": 15, \"department\": \"Engineering\", \"role\": \"Engineering Manager\", \"skills\": \"Team leadership, project management, software architecture, mentoring\", \"location\": \"Seattle\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_7\", \"name\": \"Sarah Clark\", \"experience\": 8, \"department\": \"HR\", \"role\": \"HR Manager\", \"skills\": \"Performance management, compensation planning, policy development, conflict resolution\", \"location\": \"Boston\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_8\", \"name\": \"Chris Evans\", \"experience\": 20, \"department\": \"Engineering\", \"role\": \"Senior Architect\", \"skills\": \"System design, distributed systems, cloud platforms, technical strategy\", \"location\": \"New York\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_9\", \"name\": \"Jessica Taylor\", \"experience\": 4, \"department\": \"Marketing\", \"role\": \"Marketing Specialist\", \"skills\": \"Brand management, advertising campaigns, customer analytics, creative strategy\", \"location\": \"Miami\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_10\", \"name\": \"Alex Rodriguez\", \"experience\": 18, \"department\": \"Engineering\", \"role\": \"Lead Software Engineer\", \"skills\": \"Full-stack development, React, Python, machine learning, data science\", \"location\": \"Denver\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_11\", \"name\": \"Hannah White\", \"experience\": 6, \"department\": \"HR\", \"role\": \"HR Business Partner\", \"skills\": \"Strategic HR, organizational development, change management, employee engagement\", \"location\": \"Portland\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_12\", \"name\": \"Kevin Martinez\", \"experience\": 10, \"department\": \"Engineering\", \"role\": \"DevOps Engineer\", \"skills\": \"Docker, Kubernetes, AWS, CI/CD pipelines, infrastructure automation\", \"location\": \"Phoenix\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_13\", \"name\": \"Rachel Brown\", \"experience\": 7, \"department\": \"Marketing\", \"role\": \"Marketing Director\", \"skills\": \"Strategic marketing, team leadership, budget management, campaign optimization\", \"location\": \"Atlanta\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_14\", \"name\": \"Matthew Garcia\", \"experience\": 3, \"department\": \"Engineering\", \"role\": \"Junior Software Engineer\", \"skills\": \"JavaScript, HTML/CSS, basic backend development, learning frameworks\", \"location\": \"Dallas\", \"employment_type\": \"Full-time\"},\n",
    "            {\"id\": \"employee_15\", \"name\": \"Olivia Moore\", \"experience\": 12, \"department\": \"Engineering\", \"role\": \"Principal Engineer\", \"skills\": \"Technical leadership, system architecture, performance optimization, mentoring\", \"location\": \"San Francisco\", \"employment_type\": \"Full-time\"}\n",
    "        ]\n",
    "\n",
    "        employee_documents = []\n",
    "        for employee in employees:\n",
    "            document = f\"{employee['role']} with {employee['experience']} years of experience in {employee['department']}. \"\n",
    "            document += f\"Skills: {employee['skills']}. Located in {employee['location']}. \"\n",
    "            document += f\"Employment type: {employee['employment_type']}.\"\n",
    "            employee_documents.append(document)\n",
    "\n",
    "        collection.add(\n",
    "            ids=[employee[\"id\"] for employee in employees],\n",
    "            documents=employee_documents,\n",
    "            metadatas=[{\n",
    "                \"name\": employee[\"name\"],\n",
    "                \"department\": employee[\"department\"],\n",
    "                \"role\": employee[\"role\"],\n",
    "                \"experience\": employee[\"experience\"],\n",
    "                \"location\": employee[\"location\"],\n",
    "                \"employment_type\": employee[\"employment_type\"]\n",
    "            } for employee in employees]\n",
    "        )\n",
    "\n",
    "        all_items = collection.get()\n",
    "        print(\"Collection contents:\")\n",
    "        print(f\"Number of documents: {len(all_items['documents'])}\")\n",
    "\n",
    "        def perform_advanced_search(collection, all_items):\n",
    "            try:\n",
    "                print(\"=== Similarity Search Examples ===\")\n",
    "                print(\"\\n1. Searching for Python developers:\")\n",
    "                query_text = \"Python developer with web development experience\"\n",
    "                results = collection.query(\n",
    "                    query_texts=[query_text],\n",
    "                    n_results=3\n",
    "                )\n",
    "                print(f\"Query: '{query_text}'\")\n",
    "                for i, (doc_id, document, distance) in enumerate(zip(\n",
    "                    results['ids'][0], results['documents'][0], results['distances'][0]\n",
    "                )):\n",
    "                    metadata = results['metadatas'][0][i]\n",
    "                    print(f\"  {i+1}. {metadata['name']} ({doc_id}) - Distance: {distance:.4f}\")\n",
    "                    print(f\"     Role: {metadata['role']}, Department: {metadata['department']}\")\n",
    "                    print(f\"     Document: {document[:100]}...\")\n",
    "\n",
    "                print(\"\\n2. Searching for leadership and management roles:\")\n",
    "                query_text = \"team leader manager with experience\"\n",
    "                results = collection.query(\n",
    "                    query_texts=[query_text],\n",
    "                    n_results=3\n",
    "                )\n",
    "                print(f\"Query: '{query_text}'\")\n",
    "                for i, (doc_id, document, distance) in enumerate(zip(\n",
    "                    results['ids'][0], results['documents'][0], results['distances'][0]\n",
    "                )):\n",
    "                    metadata = results['metadatas'][0][i]\n",
    "                    print(f\"  {i+1}. {metadata['name']} ({doc_id}) - Distance: {distance:.4f}\")\n",
    "                    print(f\"     Role: {metadata['role']}, Experience: {metadata['experience']} years\")\n",
    "                \n",
    "                print(\"\\n=== Metadata Filtering Examples ===\")\n",
    "                print(\"\\n3. Finding all Engineering employees:\")\n",
    "                results = collection.get(\n",
    "                    where={\"department\": \"Engineering\"}\n",
    "                )\n",
    "                print(f\"Found {len(results['ids'])} Engineering employees:\")\n",
    "                for i, doc_id in enumerate(results['ids']):\n",
    "                    metadata = results['metadatas'][i]\n",
    "                    print(f\"  - {metadata['name']}: {metadata['role']} ({metadata['experience']} years)\")\n",
    "\n",
    "                print(\"\\n4. Finding employees with 10+ years experience:\")\n",
    "                results = collection.get(\n",
    "                    where={\"experience\": {\"$gte\": 10}}\n",
    "                )\n",
    "                print(f\"Found {len(results['ids'])} senior employees:\")\n",
    "                for i, doc_id in enumerate(results['ids']):\n",
    "                    metadata = results['metadatas'][i]\n",
    "                    print(f\"  - {metadata['name']}: {metadata['role']} ({metadata['experience']} years)\")\n",
    "\n",
    "                print(\"\\n5. Finding employees in California:\")\n",
    "                results = collection.get(\n",
    "                    where={\"location\": {\"$in\": [\"San Francisco\", \"Los Angeles\"]}}\n",
    "                )\n",
    "                print(f\"Found {len(results['ids'])} employees in California:\")\n",
    "                for i, doc_id in enumerate(results['ids']):\n",
    "                    metadata = results['metadatas'][i]\n",
    "                    print(f\"  - {metadata['name']}: {metadata['location']}\")\n",
    "                \n",
    "                print(\"\\n=== Combined Search: Similarity + Metadata Filtering ===\")\n",
    "                print(\"\\n6. Finding senior Python developers in major tech cities:\")\n",
    "                query_text = \"senior Python developer full-stack\"\n",
    "                results = collection.query(\n",
    "                    query_texts=[query_text],\n",
    "                    n_results=5,\n",
    "                    where={\n",
    "                        \"$and\": [\n",
    "                            {\"experience\": {\"$gte\": 8}},\n",
    "                            {\"location\": {\"$in\": [\"San Francisco\", \"New York\", \"Seattle\"]}}\n",
    "                        ]\n",
    "                    }\n",
    "                )\n",
    "                print(f\"Query: '{query_text}' with filters (8+ years, major tech cities)\")\n",
    "                print(f\"Found {len(results['ids'][0])} matching employees:\")\n",
    "                for i, (doc_id, document, distance) in enumerate(zip(\n",
    "                    results['ids'][0], results['documents'][0], results['distances'][0]\n",
    "                )):\n",
    "                    metadata = results['metadatas'][0][i]\n",
    "                    print(f\"  {i+1}. {metadata['name']} ({doc_id}) - Distance: {distance:.4f}\")\n",
    "                    print(f\"     {metadata['role']} in {metadata['location']} ({metadata['experience']} years)\")\n",
    "                    print(f\"     Document snippet: {document[:80]}...\")\n",
    "                \n",
    "                if not results or not results['ids'] or len(results['ids'][0]) == 0:\n",
    "                    print(f'No documents found similar to \"{query_text}\"')\n",
    "                    return\n",
    "                \n",
    "                print(f'Top 3 similar documents to \"{query_text}\":')\n",
    "                for i in range(min(3, len(results['ids'][0]))):\n",
    "                    doc_id = results['ids'][0][i]\n",
    "                    score = results['distances'][0][i]\n",
    "                    text = results['documents'][0][i]\n",
    "                    if not text:\n",
    "                        print(f' - ID: {doc_id}, Text: \"Text not available\", Score: {score:.4f}')\n",
    "                    else:\n",
    "                        print(f' - ID: {doc_id}, Text: \"{text}\", Score: {score:.4f}')\n",
    "            except Exception as error:\n",
    "                print(f\"Error in advanced search: {error}\")\n",
    "        \n",
    "        perform_advanced_search(collection, all_items)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bfab6-4e2b-44fe-a35b-4ed638b79eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a17bf0-189b-4535-aeda-45fcd6a48d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created: book_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection contents:\n",
      "Number of documents: 8\n",
      "=== Book Similarity Search ===\n",
      "\n",
      "1. Finding magical fantasy adventures:\n",
      "  1. Harry Potter and the Philosopher's Stone by J.K. Rowling - Distance: 0.5385\n",
      "  2. The Lord of the Rings by J.R.R. Tolkien - Distance: 0.6017\n",
      "  3. The Hunger Games by Suzanne Collins - Distance: 0.6631\n",
      "\n",
      "=== Metadata Filtering ===\n",
      "\n",
      "2. Finding Fantasy and Science Fiction books:\n",
      "  - Harry Potter and the Philosopher's Stone: Fantasy (4.5)\n",
      "  - The Lord of the Rings: Fantasy (4.5)\n",
      "  - The Hitchhiker's Guide to the Galaxy: Science Fiction (4.2)\n",
      "  - Dune: Science Fiction (4.3)\n",
      "\n",
      "3. Finding highly-rated books (4.3+):\n",
      "  - To Kill a Mockingbird: 4.3\n",
      "  - 1984: 4.4\n",
      "  - Harry Potter and the Philosopher's Stone: 4.5\n",
      "  - The Lord of the Rings: 4.5\n",
      "  - Dune: 4.3\n",
      "\n",
      "=== Combined Search ===\n",
      "\n",
      "4. Finding highly-rated dystopian books:\n",
      "  1. 1984 (1949) - 4.4\n",
      "     Distance: 0.4764\n",
      "  2. The Hunger Games (2008) - 4.2\n",
      "     Distance: 0.6794\n",
      "  3. To Kill a Mockingbird (1960) - 4.3\n",
      "     Distance: 0.7307\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_name = \"book_collection\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"A collection for storing book data\"},\n",
    "            configuration={\n",
    "                \"hnsw\": {\"space\": \"cosine\"},\n",
    "                \"embedding_function\": ef\n",
    "            }\n",
    "        )\n",
    "        print(f\"Collection created: {collection.name}\")\n",
    "\n",
    "        books = [\n",
    "            {\n",
    "                \"id\": \"book_1\",\n",
    "                \"title\": \"The Great Gatsby\",\n",
    "                \"author\": \"F. Scott Fitzgerald\",\n",
    "                \"genre\": \"Classic\",\n",
    "                \"year\": 1925,\n",
    "                \"rating\": 4.1,\n",
    "                \"pages\": 180,\n",
    "                \"description\": \"A tragic tale of wealth, love, and the American Dream in the Jazz Age\",\n",
    "                \"themes\": \"wealth, corruption, American Dream, social class\",\n",
    "                \"setting\": \"New York, 1920s\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_2\",\n",
    "                \"title\": \"To Kill a Mockingbird\",\n",
    "                \"author\": \"Harper Lee\",\n",
    "                \"genre\": \"Classic\",\n",
    "                \"year\": 1960,\n",
    "                \"rating\": 4.3,\n",
    "                \"pages\": 376,\n",
    "                \"description\": \"A powerful story of racial injustice and moral growth in the American South\",\n",
    "                \"themes\": \"racism, justice, moral courage, childhood innocence\",\n",
    "                \"setting\": \"Alabama, 1930s\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_3\",\n",
    "                \"title\": \"1984\",\n",
    "                \"author\": \"George Orwell\",\n",
    "                \"genre\": \"Dystopian\",\n",
    "                \"year\": 1949,\n",
    "                \"rating\": 4.4,\n",
    "                \"pages\": 328,\n",
    "                \"description\": \"A chilling vision of totalitarian control and surveillance society\",\n",
    "                \"themes\": \"totalitarianism, surveillance, freedom, truth\",\n",
    "                \"setting\": \"Oceania, dystopian future\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_4\",\n",
    "                \"title\": \"Harry Potter and the Philosopher's Stone\",\n",
    "                \"author\": \"J.K. Rowling\",\n",
    "                \"genre\": \"Fantasy\",\n",
    "                \"year\": 1997,\n",
    "                \"rating\": 4.5,\n",
    "                \"pages\": 223,\n",
    "                \"description\": \"A young wizard discovers his magical heritage and begins his education at Hogwarts\",\n",
    "                \"themes\": \"friendship, courage, good vs evil, coming of age\",\n",
    "                \"setting\": \"England, magical world\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_5\",\n",
    "                \"title\": \"The Lord of the Rings\",\n",
    "                \"author\": \"J.R.R. Tolkien\",\n",
    "                \"genre\": \"Fantasy\",\n",
    "                \"year\": 1954,\n",
    "                \"rating\": 4.5,\n",
    "                \"pages\": 1216,\n",
    "                \"description\": \"An epic fantasy quest to destroy a powerful ring and save Middle-earth\",\n",
    "                \"themes\": \"heroism, friendship, good vs evil, power corruption\",\n",
    "                \"setting\": \"Middle-earth, fantasy realm\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_6\",\n",
    "                \"title\": \"The Hitchhiker's Guide to the Galaxy\",\n",
    "                \"author\": \"Douglas Adams\",\n",
    "                \"genre\": \"Science Fiction\",\n",
    "                \"year\": 1979,\n",
    "                \"rating\": 4.2,\n",
    "                \"pages\": 224,\n",
    "                \"description\": \"A humorous space adventure following Arthur Dent across the galaxy\",\n",
    "                \"themes\": \"absurdity, technology, existence, humor\",\n",
    "                \"setting\": \"Space, various planets\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_7\",\n",
    "                \"title\": \"Dune\",\n",
    "                \"author\": \"Frank Herbert\",\n",
    "                \"genre\": \"Science Fiction\",\n",
    "                \"year\": 1965,\n",
    "                \"rating\": 4.3,\n",
    "                \"pages\": 688,\n",
    "                \"description\": \"A complex tale of politics, religion, and ecology on a desert planet\",\n",
    "                \"themes\": \"power, ecology, religion, politics\",\n",
    "                \"setting\": \"Arrakis, distant future\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"book_8\",\n",
    "                \"title\": \"The Hunger Games\",\n",
    "                \"author\": \"Suzanne Collins\",\n",
    "                \"genre\": \"Dystopian\",\n",
    "                \"year\": 2008,\n",
    "                \"rating\": 4.2,\n",
    "                \"pages\": 374,\n",
    "                \"description\": \"A teenage girl fights for survival in a brutal televised competition\",\n",
    "                \"themes\": \"survival, oppression, sacrifice, rebellion\",\n",
    "                \"setting\": \"Panem, dystopian future\"\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        book_documents = []\n",
    "        for book in books:\n",
    "            document = f\"{book['title']} by {book['author']}. {book['description']} \"\n",
    "            document += f\"Themes: {book['themes']}. Setting: {book['setting']}. \"\n",
    "            document += f\"Genre: {book['genre']} published in {book['year']}.\"\n",
    "            book_documents.append(document)\n",
    "\n",
    "        collection.add(\n",
    "            ids=[book[\"id\"] for book in books],\n",
    "            documents=book_documents,\n",
    "            metadatas=[{\n",
    "                \"title\": book[\"title\"],\n",
    "                \"author\": book[\"author\"],\n",
    "                \"genre\": book[\"genre\"],\n",
    "                \"year\": book[\"year\"],\n",
    "                \"rating\": book[\"rating\"],\n",
    "                \"pages\": book[\"pages\"]\n",
    "            } for book in books]\n",
    "        )\n",
    "\n",
    "        all_items = collection.get()\n",
    "        print(\"Collection contents:\")\n",
    "        print(f\"Number of documents: {len(all_items['documents'])}\")\n",
    "\n",
    "        def perform_book_search(collection):\n",
    "            print(\"=== Book Similarity Search ===\")\n",
    "            \n",
    "            print(\"\\n1. Finding magical fantasy adventures:\")\n",
    "            results = collection.query(\n",
    "                query_texts=[\"magical fantasy adventure with friendship and courage\"],\n",
    "                n_results=3\n",
    "            )\n",
    "            for i, (doc_id, document, distance) in enumerate(zip(\n",
    "                results['ids'][0], results['documents'][0], results['distances'][0]\n",
    "            )):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                print(f\"  {i+1}. {metadata['title']} by {metadata['author']} - Distance: {distance:.4f}\")\n",
    "            \n",
    "            print(\"\\n=== Metadata Filtering ===\")\n",
    "            \n",
    "            print(\"\\n2. Finding Fantasy and Science Fiction books:\")\n",
    "            results = collection.get(\n",
    "                where={\"genre\": {\"$in\": [\"Fantasy\", \"Science Fiction\"]}}\n",
    "            )\n",
    "            for i, doc_id in enumerate(results['ids']):\n",
    "                metadata = results['metadatas'][i]\n",
    "                print(f\"  - {metadata['title']}: {metadata['genre']} ({metadata['rating']})\")\n",
    "\n",
    "            print(\"\\n3. Finding highly-rated books (4.3+):\")\n",
    "            results = collection.get(\n",
    "                where={\"rating\": {\"$gte\": 4.3}}\n",
    "            )\n",
    "            for i, doc_id in enumerate(results['ids']):\n",
    "                metadata = results['metadatas'][i]\n",
    "                print(f\"  - {metadata['title']}: {metadata['rating']}\")\n",
    "            \n",
    "            print(\"\\n=== Combined Search ===\")\n",
    "            \n",
    "            print(\"\\n4. Finding highly-rated dystopian books:\")\n",
    "            results = collection.query(\n",
    "                query_texts=[\"dystopian society control oppression future\"],\n",
    "                n_results=3,\n",
    "                where={\"rating\": {\"$gte\": 4.0}}\n",
    "            )\n",
    "            for i, (doc_id, document, distance) in enumerate(zip(\n",
    "                results['ids'][0], results['documents'][0], results['distances'][0]\n",
    "            )):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                print(f\"  {i+1}. {metadata['title']} ({metadata['year']}) - {metadata['rating']}\")\n",
    "                print(f\"     Distance: {distance:.4f}\")\n",
    "\n",
    "        perform_book_search(collection)\n",
    "    except Exception as error:\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e74ce-f146-4da8-af82-ef018ab16bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
